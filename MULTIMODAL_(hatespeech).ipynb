{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXS0W7t81f0M",
        "outputId": "b098169b-f132-4318-e48a-76e4ff6181e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vosk in /usr/local/lib/python3.10/dist-packages (0.3.45)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from vosk) (1.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vosk) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vosk) (4.66.2)\n",
            "Requirement already satisfied: srt in /usr/local/lib/python3.10/dist-packages (from vosk) (3.5.3)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from vosk) (12.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->vosk) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2024.2.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.4.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchaudio) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.2.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchvision) (1.3.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install vosk\n",
        "!pip install librosa\n",
        "!pip install torchaudio\n",
        "!pip install torchvision\n",
        "!apt-get install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def extract_audio(video_path, audio_path):\n",
        "    # Run ffmpeg command to extract audio\n",
        "    os.system(f\"ffmpeg -i {video_path} -vn -acodec pcm_s16le -ar 44100 -ac 1 {audio_path}\")\n",
        "\n",
        "# Define paths to your video folders\n",
        "folder1_path = \"/content/hate_videos\"\n",
        "folder2_path = \"/content/non_hate_videos\"\n",
        "\n",
        "# Define output folder paths for audio files\n",
        "output_folder1_path = \"/content/output_hate\"\n",
        "output_folder2_path = \"/content/output_non_hate\"\n",
        "\n",
        "# Create output folders if they don't exist\n",
        "os.makedirs(output_folder1_path, exist_ok=True)\n",
        "os.makedirs(output_folder2_path, exist_ok=True)\n",
        "\n",
        "# Iterate over files in folder 1\n",
        "for filename in os.listdir(folder1_path):\n",
        "    if filename.endswith(\".mp4\"):\n",
        "        video_path = os.path.join(folder1_path, filename)\n",
        "        audio_path = os.path.join(output_folder1_path, filename.replace(\".mp4\", \".wav\"))\n",
        "        extract_audio(video_path, audio_path)\n",
        "\n",
        "# Iterate over files in folder 2\n",
        "for filename in os.listdir(folder2_path):\n",
        "    if filename.endswith(\".mp4\"):\n",
        "        video_path = os.path.join(folder2_path, filename)\n",
        "        audio_path = os.path.join(output_folder2_path, filename.replace(\".mp4\", \".wav\"))\n",
        "        extract_audio(video_path, audio_path)\n"
      ],
      "metadata": {
        "id": "Rs4IK6bmbnMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
        "!unzip vosk-model-small-en-us-0.15.zip -d vosk-model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEaRzcS6btcb",
        "outputId": "78a08f11-0642-4de7-d206-5f7c82a50fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-24 09:47:48--  https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
            "Resolving alphacephei.com (alphacephei.com)... 188.40.21.16, 2a01:4f8:13a:279f::2\n",
            "Connecting to alphacephei.com (alphacephei.com)|188.40.21.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41205931 (39M) [application/zip]\n",
            "Saving to: ‘vosk-model-small-en-us-0.15.zip.2’\n",
            "\n",
            "vosk-model-small-en 100%[===================>]  39.30M  19.4MB/s    in 2.0s    \n",
            "\n",
            "2024-04-24 09:47:51 (19.4 MB/s) - ‘vosk-model-small-en-us-0.15.zip.2’ saved [41205931/41205931]\n",
            "\n",
            "Archive:  vosk-model-small-en-us-0.15.zip\n",
            "replace vosk-model/vosk-model-small-en-us-0.15/am/final.mdl? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wave\n",
        "import vosk\n",
        "\n",
        "# Initialize Vosk model\n",
        "model_path = \"/content/vosk-model/vosk-model-small-en-us-0.15\"\n",
        "vosk.SetLogLevel(-1)\n",
        "model = vosk.Model(model_path)\n",
        "\n",
        "# Function to transcribe audio\n",
        "def transcribe_audio(audio_path):\n",
        "    wf = wave.open(audio_path, \"rb\")\n",
        "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
        "        print(\"Audio file must be WAV format mono PCM.\")\n",
        "        exit(1)\n",
        "    rec = vosk.KaldiRecognizer(model, wf.getframerate())\n",
        "    transcribed_text = \"\"\n",
        "    while True:\n",
        "        data = wf.readframes(4000)\n",
        "        if len(data) == 0:\n",
        "            break\n",
        "        if rec.AcceptWaveform(data):\n",
        "            result = rec.Result()\n",
        "            transcribed_text += result\n",
        "    result = rec.FinalResult()\n",
        "    transcribed_text += result\n",
        "    return transcribed_text\n",
        "\n",
        "# Define paths to your audio folders\n",
        "folder1_path = \"/content/output_hate\"\n",
        "folder2_path = \"/content/output_non_hate\"\n",
        "\n",
        "# Transcribe audio files in folder 1\n",
        "transcribed_texts_folder1 = []\n",
        "for filename in os.listdir(folder1_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_path = os.path.join(folder1_path, filename)\n",
        "        transcribed_text = transcribe_audio(audio_path)\n",
        "        transcribed_texts_folder1.append(transcribed_text)\n",
        "\n",
        "# Transcribe audio files in folder 2\n",
        "transcribed_texts_folder2 = []\n",
        "for filename in os.listdir(folder2_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_path = os.path.join(folder2_path, filename)\n",
        "        transcribed_text = transcribe_audio(audio_path)\n",
        "        transcribed_texts_folder2.append(transcribed_text)\n",
        "\n",
        "# Now you have transcribed texts for each folder\n",
        "# You can pass these transcribed texts to your BERT model for feature extraction\n"
      ],
      "metadata": {
        "id": "-ZiIpOrUcCpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0qc7jkPfcU7",
        "outputId": "98a93d63-3e07-4c92-dcfd-47371e80cbf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "# Load pre-trained BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to extract BERT features\n",
        "def extract_bert_features(texts):\n",
        "    # Tokenize input texts\n",
        "    tokenized_texts = tokenizer(texts, padding=True, truncation=True, return_tensors='tf')\n",
        "    # Forward pass through BERT model\n",
        "    outputs = model(tokenized_texts)\n",
        "    # Extract features from BERT output\n",
        "    pooled_output = outputs.pooler_output\n",
        "    return pooled_output\n",
        "\n",
        "# Example usage:\n",
        "# Extract BERT features for transcribed texts in folder 1\n",
        "bert_features_folder1 = extract_bert_features(transcribed_texts_folder1)\n",
        "\n",
        "# Extract BERT features for transcribed texts in folder 2\n",
        "bert_features_folder2 = extract_bert_features(transcribed_texts_folder2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYGJtL4BffDr",
        "outputId": "8a1d0148-d7ab-4b40-d93c-f0f5680c1a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_features_folder1.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZSaRWO3KNHP",
        "outputId": "d60143bc-ac29-4629-c2df-690faaa1fe76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([20, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_features_folder2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQDPKn6_KZU-",
        "outputId": "7279d943-9da6-4a20-ae1c-8e96b2f7dece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([20, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "# Function to extract frames from videos\n",
        "def extract_frames(video_path, num_frames=100):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frames = []\n",
        "    for _ in range(num_frames):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB format\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "# Function to extract features from frames using ViT\n",
        "def extract_vit_features(frames):\n",
        "    model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    preprocessed_frames = [preprocess_input(cv2.resize(frame, (224, 224))) for frame in frames]\n",
        "    features = model.predict(np.array(preprocessed_frames))\n",
        "    return features\n",
        "\n",
        "# Define paths to your video folders\n",
        "hate_videos_path = \"/content/hate_videos\"\n",
        "non_hate_videos_path = \"/content/non_hate_videos\"\n",
        "\n",
        "# Extract features for hate videos\n",
        "hate_video_features = []\n",
        "for filename in os.listdir(hate_videos_path):\n",
        "    if filename.endswith(\".mp4\"):\n",
        "        video_path = os.path.join(hate_videos_path, filename)\n",
        "        frames = extract_frames(video_path)\n",
        "        features = extract_vit_features(frames)\n",
        "        hate_video_features.append(features)\n",
        "\n",
        "# Extract features for non-hate videos\n",
        "non_hate_video_features = []\n",
        "for filename in os.listdir(non_hate_videos_path):\n",
        "    if filename.endswith(\".mp4\"):\n",
        "        video_path = os.path.join(non_hate_videos_path, filename)\n",
        "        frames = extract_frames(video_path)\n",
        "        features = extract_vit_features(frames)\n",
        "        non_hate_video_features.append(features)\n",
        "\n",
        "# Now you have extracted ViT features for frames from all hate and non-hate videos\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzEr9ayAKhxr",
        "outputId": "1295d2a6-8bca-4e46-c854-76767e4122f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 67s 15s/step\n",
            "4/4 [==============================] - 61s 14s/step\n",
            "4/4 [==============================] - 60s 13s/step\n",
            "4/4 [==============================] - 59s 13s/step\n",
            "4/4 [==============================] - 60s 13s/step\n",
            "4/4 [==============================] - 60s 13s/step\n",
            "4/4 [==============================] - 61s 14s/step\n",
            "4/4 [==============================] - 61s 14s/step\n",
            "4/4 [==============================] - 67s 14s/step\n",
            "4/4 [==============================] - 61s 14s/step\n",
            "4/4 [==============================] - 60s 14s/step\n",
            "4/4 [==============================] - 61s 14s/step\n",
            "4/4 [==============================] - 65s 15s/step\n",
            "4/4 [==============================] - 62s 14s/step\n",
            "4/4 [==============================] - 61s 14s/step\n",
            "4/4 [==============================] - 60s 14s/step\n",
            "4/4 [==============================] - 62s 13s/step\n",
            "4/4 [==============================] - 60s 14s/step\n",
            "4/4 [==============================] - 59s 14s/step\n",
            "4/4 [==============================] - 61s 13s/step\n",
            "4/4 [==============================] - 61s 13s/step\n",
            "4/4 [==============================] - 66s 16s/step\n",
            "4/4 [==============================] - 60s 13s/step\n",
            "4/4 [==============================] - 62s 14s/step\n",
            "4/4 [==============================] - 59s 13s/step\n",
            "4/4 [==============================] - 65s 15s/step\n",
            "4/4 [==============================] - 60s 13s/step\n",
            "4/4 [==============================] - 61s 14s/step\n",
            "4/4 [==============================] - 61s 14s/step\n",
            "4/4 [==============================] - 66s 14s/step\n",
            "4/4 [==============================] - 61s 14s/step\n",
            "4/4 [==============================] - 59s 13s/step\n",
            "4/4 [==============================] - 60s 14s/step\n",
            "4/4 [==============================] - 60s 14s/step\n",
            "4/4 [==============================] - 63s 14s/step\n",
            "4/4 [==============================] - 60s 14s/step\n",
            "4/4 [==============================] - 61s 14s/step\n",
            "4/4 [==============================] - 60s 14s/step\n",
            "4/4 [==============================] - 63s 14s/step\n",
            "4/4 [==============================] - 59s 13s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "\n",
        "# Function to extract MFCC features from audio file\n",
        "def extract_mfcc(audio_path, num_mfcc=40, max_mfcc_length=500):\n",
        "    # Load audio file\n",
        "    y, sr = librosa.load(audio_path, sr=None)\n",
        "    # Extract MFCC features\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=num_mfcc)\n",
        "    # Pad or truncate MFCC features to the fixed length\n",
        "    if mfccs.shape[1] >= max_mfcc_length:\n",
        "        mfccs = mfccs[:, :max_mfcc_length]\n",
        "    else:\n",
        "        mfccs = np.pad(mfccs, ((0, 0), (0, max_mfcc_length - mfccs.shape[1])), mode='constant', constant_values=0)\n",
        "    # Normalize MFCCs\n",
        "    mfccs = (mfccs - np.mean(mfccs)) / np.std(mfccs)\n",
        "    return mfccs\n",
        "\n",
        "# Define paths to your audio folders\n",
        "folder1_path = \"/content/output_hate\"\n",
        "folder2_path = \"/content/output_non_hate\"\n",
        "\n",
        "max_mfcc_length = 790\n",
        "\n",
        "# Extract MFCC features for audio files in folder 1 (hate)\n",
        "mfcc_features_folder1 = []\n",
        "for filename in os.listdir(folder1_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_path = os.path.join(folder1_path, filename)\n",
        "        mfccs = extract_mfcc(audio_path, max_mfcc_length=max_mfcc_length)\n",
        "        mfcc_features_folder1.append(mfccs)\n",
        "\n",
        "# Extract MFCC features for audio files in folder 2 (non-hate)\n",
        "mfcc_features_folder2 = []\n",
        "for filename in os.listdir(folder2_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audio_path = os.path.join(folder2_path, filename)\n",
        "        mfccs = extract_mfcc(audio_path, max_mfcc_length=max_mfcc_length)\n",
        "        mfcc_features_folder2.append(mfccs)\n"
      ],
      "metadata": {
        "id": "EzKgA6y1JuiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming mfcc_features_folder1 is a list of MFCC features\n",
        "mfcc_lengths = [len(mfcc) for mfcc in mfcc_features_folder2]\n",
        "\n",
        "# Check if all lengths are the same\n",
        "if len(set(mfcc_lengths)) == 1:\n",
        "    print(\"All MFCC features have the same length.\")\n",
        "else:\n",
        "    print(\"MFCC features have varying lengths.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhLZo_85q07u",
        "outputId": "e5c4abdf-79fb-4d90-c334-7bbc951dba26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All MFCC features have the same length.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UEjbIUfLqz0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Concatenate, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "bert_features_folder2_np = np.array(bert_features_folder2)\n",
        "bert_features_folder1_np = np.array(bert_features_folder1)\n",
        "\n",
        "mfcc_features_folder1_np = np.array(mfcc_features_folder1)\n",
        "mfcc_features_folder2_np = np.array(mfcc_features_folder2)\n",
        "hate_video_features_np = np.array(hate_video_features)\n",
        "non_hate_video_features_np = np.array(non_hate_video_features)\n",
        "# num_samples = len(hate_video_features)\n",
        "# num_mfcc_features = len(mfcc_features_folder1[0])  # Assuming all MFCC features have the same length\n",
        "# mfcc_features_folder1_reshaped = mfcc_features_folder1_np.reshape(num_samples, num_mfcc_features)\n",
        "# mfcc_features_folder2_reshaped = mfcc_features_folder2_np.reshape(num_samples, num_mfcc_features)\n"
      ],
      "metadata": {
        "id": "2TN-2al5ZZki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(hate_video_features_np.shape)\n",
        "print(mfcc_features_folder2_np.shape)\n",
        "print(bert_features_folder2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DxuNuUir4i_",
        "outputId": "c354dd78-abcb-4192-db5d-aab67d198c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 100, 7, 7, 512)\n",
            "(20, 40, 790)\n",
            "(20, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# Define fusion model architecture\n",
        "class FusionModel(Model):\n",
        "    def __init__(self):\n",
        "        super(FusionModel, self).__init__()\n",
        "        self.bert_dense = layers.Dense(256, activation='relu')\n",
        "        self.mfcc_dense = layers.Dense(256, activation='relu')\n",
        "        self.mfcc_flatten = layers.Flatten()  # Add flatten layer for MFCC output\n",
        "        self.video_conv = layers.Conv3D(256, (3, 3, 3), activation='relu')\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.fusion_dense = layers.Dense(512, activation='relu')\n",
        "        self.output_layer = layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        bert_features, mfcc_features, video_features = inputs\n",
        "        bert_output = self.bert_dense(bert_features)\n",
        "        mfcc_output = self.mfcc_dense(mfcc_features)\n",
        "        mfcc_output = self.mfcc_flatten(mfcc_output)  # Flatten MFCC output\n",
        "        video_output = self.video_conv(video_features)\n",
        "        video_output = self.flatten(video_output)\n",
        "        combined_features = tf.concat([bert_output, mfcc_output, video_output], axis=-1)\n",
        "        fusion_output = self.fusion_dense(combined_features)\n",
        "        output = self.output_layer(fusion_output)\n",
        "        return output\n",
        "\n",
        "\n",
        "# Initialize fusion model\n",
        "fusion_model = FusionModel()\n",
        "\n",
        "# Compile fusion model\n",
        "fusion_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Prepare input data\n",
        "hate_labels = np.ones((len(bert_features_folder1), 1))  # Assuming labels for hate samples are 1\n",
        "non_hate_labels = np.zeros((len(bert_features_folder2), 1))  # Assuming labels for non-hate samples are 0\n",
        "labels = np.concatenate([hate_labels, non_hate_labels], axis=0)\n",
        "bert_features = np.concatenate([bert_features_folder1, bert_features_folder2], axis=0)\n",
        "mfcc_features = np.concatenate([mfcc_features_folder1_np, mfcc_features_folder2_np], axis=0)\n",
        "video_features = np.concatenate([hate_video_features_np, non_hate_video_features_np], axis=0)\n",
        "\n",
        "# Train fusion model\n",
        "fusion_model.fit([bert_features, mfcc_features, video_features], labels, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate fusion model\n",
        "loss, accuracy = fusion_model.evaluate([bert_features, mfcc_features, video_features], labels)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "UuHw8yBBHT6V",
        "outputId": "aa520114-fad7-4164-ebaa-668d017d8821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'bert_features_folder1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-352b32528c33>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Prepare input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mhate_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_features_folder1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming labels for hate samples are 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mnon_hate_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_features_folder2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming labels for non-hate samples are 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhate_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_hate_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bert_features_folder1' is not defined"
          ]
        }
      ]
    }
  ]
}